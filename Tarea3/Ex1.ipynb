{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/MARCA-Color.jpg\" title=\"Title text\" width=\"50%\" height=\"50%\" />\n",
    "\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "<h1 align='center'> INF-395/477 Redes Neuronales Artificiales II-2018 </h1>\n",
    "\n",
    "<H3 align='center'> Tarea 2 - Redes Convolucionales y sus aplicaciones </H3>\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "### Pregunta 2. Transfer Learning.\n",
    "\n",
    "Integrantes:\n",
    "\n",
    "- Christian Da Rocha, ROL: 2018.90.251-9\n",
    "- Rodrigo Hermosilla, ROL: 95.74.144-4\n",
    "\n",
    "\n",
    "##### Carga inicial de librerias\n",
    "> En la siguiente sección y de manera previa se cargan todas las librerías necesarias para el ejercicio. Para efectos de mantener cierto orden con el código de las preguntas del ejercicio, se determino que todas las cargas se realizaran previamente, no obstante, se entiende que esto podría generar alguna ineficiencia en el consumo de recursos, pero que suponemos es marginal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, Dense, Dropout, Bidirectional, CuDNNGRU, GRU\n",
    "from sklearn.metrics import f1_score\n",
    "from heapq import nlargest\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from sklearn.metrics import classification as classification_metrics\n",
    "import sklearn.datasets\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, OneHotEncoder\n",
    "import random,sys\n",
    "from keras.callbacks import LambdaCallback\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pregunta A.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Nota: </b>Para efectos de mejorar la modularización, el ejercicio construye una serie de funciones, permitiendo además su reutilización en distintos instantes.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 281837: expected 25 fields, saw 34\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>prev-iob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thousand</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>__START1__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>demonstr</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>have</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>march</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lemma           word  pos tag    prev-iob\n",
       "0  thousand      Thousands  NNS   O  __START1__\n",
       "1        of             of   IN   O           O\n",
       "2  demonstr  demonstrators  NNS   O           O\n",
       "3      have           have  VBP   O           O\n",
       "4     march        marched  VBN   O           O"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ner = pd.read_csv(\"ner.csv\", encoding =\"cp1252\", error_bad_lines=False)\n",
    "df_ner.dropna(inplace=True)\n",
    "dataset = df_ner.loc[:,[\"lemma\",\"word\",\"pos\",\"tag\",\"prev-iob\"]]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma         thousand\n",
      "word         Thousands\n",
      "pos                NNS\n",
      "tag                  O\n",
      "prev-iob    __START1__\n",
      "Name: 0, dtype: object \n",
      "\n",
      " lemma         kill\n",
      "word        killed\n",
      "pos            VBN\n",
      "tag              O\n",
      "prev-iob         O\n",
      "Name: 27, dtype: object \n",
      "\n",
      " lemma         explod\n",
      "word        exploded\n",
      "pos              VBD\n",
      "tag                O\n",
      "prev-iob           O\n",
      "Name: 1050783, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataset.loc[0],\"\\n\\n\",dataset.loc[27],\"\\n\\n\",dataset.loc[1050783])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataCreater():\n",
    "    dataX,dataY = [],[]\n",
    "    lemmas,labels = set(), set()\n",
    "    sentence= []\n",
    "    labels_sentence = []\n",
    "    for fila in dataset.values:\n",
    "        if fila[-1]==\"__START1__\": \n",
    "            dataX.append(np.asarray(sentence))\n",
    "            dataY.append(np.asarray(labels_sentence))\n",
    "            sentence= []\n",
    "            labels_sentence = []\n",
    "        lemmas.add(fila[0])\n",
    "        labels.add(fila[3])\n",
    "        sentence.append(fila[0])\n",
    "        labels_sentence.append(fila[3])\n",
    "    datax = np.asarray(dataX[1:])\n",
    "    datay = np.asarray(dataY[1:])\n",
    "    return datax, datay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Porque las palabras en la columna Lemma no están en las letras mayúsculas, ninguna palabra también esta en el plural y todos los verbos están en la forma estándar.Mirar ejemplo abajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de dataX = 48081 \n",
      "Dimensiones de dataY = 48081\n",
      "['thousand' 'of' 'demonstr' 'have' 'march' 'through' 'london' 'to'\n",
      " 'protest' 'the' 'war' 'in' 'iraq' 'and' 'demand' 'the' 'withdraw' 'of'\n",
      " 'british' 'troop' 'from' 'that' 'countri' '.'] ['O' 'O' 'O' 'O' 'O' 'O' 'B-geo' 'O' 'O' 'O' 'O' 'O' 'B-geo' 'O' 'O' 'O'\n",
      " 'O' 'O' 'B-gpe' 'O' 'O' 'O' 'O' 'O']\n"
     ]
    }
   ],
   "source": [
    "dataX, dataY = dataCreater()\n",
    "print(\"Dimensiones de dataX =\",len(dataX),\"\\nDimensiones de dataY =\",len(dataY))\n",
    "print(dataX[0], dataY[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pregunta B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrayNumber():\n",
    "    Number = []\n",
    "    for i in range(len(dataX)):\n",
    "        Number.append(len(dataX[i]))\n",
    "    return Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordSplit():\n",
    "    word = []\n",
    "    for i in range(len(dataX)):\n",
    "        for k in range(len(dataX[i])):\n",
    "            word.append(dataX[i][k])\n",
    "    word = list(set(word))\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordCounter():\n",
    "    num = 0\n",
    "    for i in range(len(dataX)):\n",
    "        for k in range(len(dataX[i])):\n",
    "            num += 1\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numberWord():\n",
    "    words = newDataX\n",
    "    counts = {}\n",
    "    for word in words:\n",
    "        if word not in counts:\n",
    "            counts[word] = 0\n",
    "        counts[word] += 1\n",
    "    counts.pop(',', None)\n",
    "    counts.pop('.', None)\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertData():\n",
    "    newDatax = []\n",
    "    for i in range (len(dataX)):\n",
    "        for k in range(len(dataX[i])):\n",
    "            newDatax.append(dataX[i][k])     \n",
    "    newDatay = []\n",
    "    for i in range (len(dataY)):\n",
    "        for k in range(len(dataY[i])):\n",
    "            newDatay.append(dataY[i][k])\n",
    "    return newDatax, newDatay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphMakerDest():\n",
    "    numbers = [0]*len(arrayNum)\n",
    "    for i in range(len(arrayNum)):\n",
    "        numbers[arrayNum[i]] += 1\n",
    "    plt.plot(numbers,'r-', linewidth = 1.5)\n",
    "    plt.axis([min(arrayNum)-1,max(arrayNum)+1, 0, max(numbers)+50])\n",
    "    plt.ylabel('Distribución')\n",
    "    plt.xlabel('Palabras')\n",
    "    plt.title('Cuantidad de palabras en uno Array')\n",
    "    plt.show()\n",
    "    print('Numero de palabras :',wordCo,'\\nNumero de palabras que no sin repticion :',len(wordSp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de palabras : 1050786 \n",
      "Numero de palabras que no sin repticion : 20243\n"
     ]
    }
   ],
   "source": [
    "wordSp = wordSplit()\n",
    "wordCo = wordCounter()\n",
    "newDataX,newDataY = convertData()\n",
    "arrayNum = arrayNumber()\n",
    "graphMakerDest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphWordDes():\n",
    "    plt.plot(list(dictWord.values()),'bo', markersize=2)\n",
    "    plt.axis([0, len(wordSp), 0, max(dictWord.values())*1.07])\n",
    "    plt.ylabel('Cuantidad')\n",
    "    plt.xlabel('Palabras')\n",
    "    plt.title('Palabra que más aparecen')\n",
    "    plt.show()\n",
    "    print('Cinco palabras que más aparecen',nlargest(5, dictWord, key=dictWord.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ0AAAEWCAYAAAC9qEq5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzt3Xu8HGWd5/HPlxxuAiEJBBaTQFAzjphZMTlCXNcrTgg4GFxFQdZERBM1io7XoLMD3mZ0HC+LIoKCJorDRUUyrhgjoM643E64X9QEiORAJJGEEIEVE3/7Rz1tiqZv55zq6u5zvu/Xq19d9dRTVU89VV2/fp6qrlZEYGZmVoZdOl0AMzMbOxx0zMysNA46ZmZWGgcdMzMrjYOOmZmVxkHHzMxK46BjHSfpZZIGW8z7Zkn/2e4ydTNJL5T0K0njO10Ws6Fy0LHCSFon6XFJf5D0oKRvSNq70+UaTSTtDnwJeH1EPNLp8pgNlYOOFe24iNgbmAW8APiHThVEmdF2jP8V8A8RcWunC9LIKK17K4APCmuLiLgfuAKYCSDpFEl3Sdom6R5Ji+vNK2mppLtT3jslveapWfQlSVtTN9NRuQk/k/QpSb8EHgOeMcR1j5P0r5J+n/IukRSS+tL0dZJemct/pqRv58bnSPq/kh6WdIuklzVY1zpJH5R0q6RHJZ0v6UBJV6Sy/lTSxFz+S4FVwMWSfiHpublpx6a62ibpfkkfqLPOZ0q6StJDaRsvlDShqkynp2VtSa3VPdK0iZJ+KGlTmvZDSVOb1P2+abs2pHJ9UtK43Dxvy+2bOyXNSulPl/S9tK57JZ1WVeeXSFqe5rtDUn+9erYuExF++VXIC1gHvDINTwPuAD6Rxl8FPBMQ8FKyk9KsNO1lwGBuOScATyf7UvQG4FHgoDTtzcB24O+BXdP0rcCkNP1nwH3Ac4G+lKfuumtsw9uBX6XyTwKuBgLoq97GNH4m8O00PAV4CDg2lf1v0/jkBvV1LXBgmncjcCPwfGB34CrgjFz+twL7pGlfBG7OTdsAvDgNT2ywfc9K5dodmAz8AvhiVZluz23/L4FPpmn7Aa8FnpbKcSnwg9y8ter+B8C5wF7AAcD1wOLcfr6frEWsVLZDUt2tBv4R2A14BnAPcHSuzv9fqudxwD8D13b6+PerxfNEpwvg1+h5pRPWH4CHgd8CXwH2rJP3B8B70vDLyAWdGnlvBuan4TcDDwDKTb8eeFMa/hnw8Sbl/Mu6a0y7Cnh7bnwurQedDwPfqlreSmBhg/o6OTf+PeCc3Pi78yf1qnknpHLtm8bvAxYD44e4z44HbqoqU377jwXurjPv4cCW3PiT6p4smP4xfwwAJwFX5+rmKfsBOBK4ryrtdOAbuTr/aW7aYcDjnT7+/Wrt1YdZsY6PiJ9WJ0o6BjiD7JrELmTflm+rtQBJC4D3AdNT0t7A/rks90c62yS/JWsZVawf7rrTcvLz/7ZOvloOAU6QdFwubVey1lI9D+aGH68xvjdAuj7yj2Stg/HAjpRnf7KW3mvJrp99WtKtwNKIuKZ6ZZIOAM4CXkzWWtkF2FKVrXr7n57mfRrwBWAeWWsKYB9J4yJiR415DyHb/g2SKmm75PJMA+6uLmOa7+mSHs6ljQP+Izf+u9zwY8AekvoiYnuN5VkXcdCxtkt3XH0PWABcHhF/kvQDsi6V6ryHAF8DjgKuiYgdkm6uyjtFknKB52BgRW76XwLSUNadbCA7GVYcXDX9UbKgVfFfcsPryVo6b6uz7JE4iSzgvDIiNqRrPZtJ2xERNwDzJe0KvAu4hCdvR8U/k9XPf42IhyQdD3y5Kk/19j+Qht8PPBs4MiJ+J+lw4CaeXJf5LwPryVo6+9cJBuvJuj1rpd8bETNqTLMe5xsJrAy7kV1D2ARsTy2PuXXy7kV24toE2Q0IpJsRcg4ATpO0q6QTgOcAPypg3ZCdrE+TNDWd2JdWTb8ZODGtux94XW7at4HjJB2dbkjYQ9lvkKYychPIWjePS9oL+FRlgqTdJJ0sad+I+BPwCDtbQtX2IXWBSpoCfLBGniVp+ycBHwEuzs37eJp3Elnrsa6I2AD8BPicpPGSdkk3Mrw0Zfk68AFJs5V5VvrScT3wiKQPS9oz1eVMSS9oVknW/Rx0rO0iYhtwGtkJfQvwRp7cMsnnvRP4HHANWVfT35BdzM67DpgB/J7s5Pu6iHhopOtOvkZ2reEWsov636+a/r/Ivp1vAT4GfCe3rvXAfLIT9Sayb+wfpJjP2TLgXmAQuJPsBoS8NwHrJD1CdjPE/6yznI+R3c6+Ffg/PHX7INumn5BdvL8H+GRK/yKwJ1m9Xwv8uIVyLyAL/HeS1dl3gYMAIuJSsv33HWAb2bW2Samr7jiya0b3pvV9Hdi3hfVZl9OTu8bNLE/SdLIT365j4XqBpHXAW2tdlzMrgls6ZmZWGgcdMzMrjbvXzMysNG7pmJlZacbc73T233//mD59eqeLYWbWM1avXv37iJhcxLLGXNCZPn06AwMDnS6GmVnPkDSUJ3M05O41MzMrjYOOmZmVxkHHzMxK46BjZmalcdAxM7PSOOiYmVlpHHTMzKw0DjpmZlYaBx0zMyuNg46ZmZXGQcfMzErjoGNmZqVx0DGznrBkCfT1Ze/Wuxx0zKwnnHsu7NiRvVvvctAxs56weDGMG5e9W+8ac39X3d/fH/4/HTOz1klaHRH9RSzLLR0zMyuNg46ZmZXGQcfMzErjoGNmZqVx0DEzs9I46JiZWWkcdMzMrDRtDTqSJkj6rqRfSbpL0gslTZK0StKa9D4x5ZWksyStlXSrpFm55SxM+ddIWphLny3ptjTPWZLUzu0xM7ORaXdL538DP46IvwaeB9wFLAWujIgZwJVpHOAYYEZ6LQLOAZA0CTgDOBI4AjijEqhSnkW5+ea1eXvMzGwE2hZ0JI0HXgKcDxART0TEw8B8YFnKtgw4Pg3PB5ZH5lpggqSDgKOBVRGxOSK2AKuAeWna+Ii4JrLHKizPLcvMzLpQO1s6zwA2Ad+QdJOkr0vaCzgwIjYApPcDUv4pwPrc/IMprVH6YI30p5C0SNKApIFNmzaNfMvMzGxY2hl0+oBZwDkR8XzgUXZ2pdVS63pMDCP9qYkR50VEf0T0T548uXGpzcysbdoZdAaBwYi4Lo1/lywIPZi6xkjvG3P5p+Xmnwo80CR9ao10MzPrUm0LOhHxO2C9pGenpKOAO4EVQOUOtIXA5Wl4BbAg3cU2B9iaut9WAnMlTUw3EMwFVqZp2yTNSXetLcgty8zMulBfm5f/buBCSbsB9wCnkAW6SySdCtwHnJDy/gg4FlgLPJbyEhGbJX0CuCHl+3hEbE7D7wC+CewJXJFeZmbWpfx/OmZm1pD/T8fMzHqSg46ZmZXGQcfMzErjoGNmZqVx0DEzs9I46JiZWWkcdMzMrDQOOmZmVhoHHTMzK42DjpmZlcZBx8zMSuOgY2ZmpXHQMTOz0jjomJlZaRx0zMysNA46ZmZWGgcdMzMrjYOOmZmVxkHHzMxK46BjZmalcdAxM7PSOOiYmVlpHHTMzKw0bQ06ktZJuk3SzZIGUtokSaskrUnvE1O6JJ0laa2kWyXNyi1nYcq/RtLCXPrstPy1aV61c3vMzGxkymjpvDwiDo+I/jS+FLgyImYAV6ZxgGOAGem1CDgHsiAFnAEcCRwBnFEJVCnPotx889q/OWZmNlyd6F6bDyxLw8uA43PpyyNzLTBB0kHA0cCqiNgcEVuAVcC8NG18RFwTEQEszy3LzMy6ULuDTgA/kbRa0qKUdmBEbABI7wek9CnA+ty8gymtUfpgjfSnkLRI0oCkgU2bNo1wk8zMbLj62rz8F0XEA5IOAFZJ+lWDvLWux8Qw0p+aGHEecB5Af39/zTxmZtZ+bW3pRMQD6X0jcBnZNZkHU9cY6X1jyj4ITMvNPhV4oEn61BrpZmbWpdoWdCTtJWmfyjAwF7gdWAFU7kBbCFyehlcAC9JdbHOAran7bSUwV9LEdAPBXGBlmrZN0px019qC3LLMzKwLtbN77UDgsnQXcx/wnYj4saQbgEsknQrcB5yQ8v8IOBZYCzwGnAIQEZslfQK4IeX7eERsTsPvAL4J7AlckV5mZtallN34NXb09/fHwMBAp4thZtYzJK3O/exlRPxEAjMzK42DjpmZlcZBx8zMSuOgY2ZmpXHQMTOz0jjomJlZaRx0zMysNA46ZmZWGgcdMzMrjYOOmZmVxkHHzMxK46BjZmalcdAxM7PSOOiYmVlpHHTMzKw0DjpmZlYaBx0zMyuNg46ZmZXGQcfMzErjoGNmZqVx0DEzs9L0NZoo6X2NpkfE54stjpmZjWbNWjr7pFc/8A5gSnq9HTislRVIGifpJkk/TOOHSrpO0hpJF0vaLaXvnsbXpunTc8s4PaX/WtLRufR5KW2tpKWtb7aZmXVCw6ATER+LiI8B+wOzIuL9EfF+YDYwtcV1vAe4Kzf+GeALETED2AKcmtJPBbZExLOAL6R8SDoMOBF4LjAP+EoKZOOAs4FjyALgSSmvmZl1qVav6RwMPJEbfwKY3mwmSVOBVwFfT+MCXgF8N2VZBhyfhuencdL0o1L++cBFEfHHiLgXWAsckV5rI+KeiHgCuCjlNTOzLtXwmk7Ot4DrJV0GBPAaYHkL830R+BBZFx3AfsDDEbE9jQ+SddeR3tcDRMR2SVtT/inAtbll5udZX5V+ZK1CSFoELAI4+OCDWyi2mZm1Q0stnYj4FPAWsu6wh4FTIuKfGs0j6e+AjRGxOp9ca/FNpg01/amJEedFRH9E9E+ePLlBqc3MrJ1abekQEaslrQf2AJB0cETc12CWFwGvlnRsmmc8WctngqS+1NqZCjyQ8g8C04BBSX3AvsDmXHpFfp566WZm1oVaaulIerWkNcC9wM/T+xWN5omI0yNiakRMJ7sR4KqIOBm4GnhdyrYQuDwNr0jjpOlXRUSk9BPT3W2HAjOA64EbgBnpbrjd0jpWtLI9ZmbWGa3eSPAJYA7wm4g4FHgl8MthrvPDwPskrSW7ZnN+Sj8f2C+lvw9YChARdwCXAHcCPwaWRMSO1FJ6F7CS7O64S1JeMzPrUsoaE00ySQMR0S/pFuD5EfFnSddHxBHtL2Kx+vv7Y2BgoNPFMDPrGZJWR0R/Ectq9ZrOw5L2Bn4BXChpI7C9yTxmZmZP0mr32nzgceDvybq47gaOa1ehzMxsdGqppRMRj+ZGl9XNaGZm1kCzB35uo85vXwAiYnzhJTIzs1GrYdCJiH0AJH0c+B3ZkwkEnMzOpwyYmZm1pNVrOkdHxFciYltEPBIR5wCvbWfBzMxs9Gk16OyQdHJ6uvMukk4GdrSzYGZmNvq0GnTeCLweeDC9TkhpZmZmLWv17rV1+G8DzMxshJrdvfahiPgXSV+ixl1sEXFa20pmZmajTrOWTuUfP/3cGDMzG7Fmt0z/exp8LCIuzU+TdELbSmVmZqNSqzcSnN5impmZWV3NrukcAxwLTJF0Vm7SePzATzMzG6Jm13QeILue82og/7fT28ge/mlmZtayZtd0bgFukfSdiPhTSWUyM7NRqtX/0zlC0pnAIWkeARERz2hXwczMbPRpNeicT9adtho//sbMzIap1aCzNSKuaGtJzMxs1Gs16Fwt6bPA94E/VhIj4sa2lMrMzEalVoPOkem9P5cWwCuKLY6ZmY1mrT7w8+XtLoiZmY1+rbZ0kPQq4LnAHpW0iPh4OwplZmajU0uPwZH0VeANwLvJbpc+gez26Ubz7CHpekm3SLpD0sdS+qGSrpO0RtLFknZL6bun8bVp+vTcsk5P6b+WdHQufV5KWytp6RC33czMStbqs9f+W0QsALZExMeAFwLTmszzR+AVEfE84HBgnqQ5wGeAL0TEDGALcGrKf2pa/rOAL6R8SDoMOJGslTUP+Er6B9NxwNnAMcBhwEkpr5mZdalWg87j6f0xSU8H/gQc2miGyPwhje6aXpWbD76b0pcBx6fh+WmcNP0oSUrpF0XEHyPiXmAtcER6rY2IeyLiCeAi/EdzZmZdrdWg80NJE4DPAjcC68hO8g2lFsnNwEZgFXA38HBEVB4WOghMScNTgPUAafpWYL98etU89dJrlWORpAFJA5s2bWq6sWZm1h6t3r32iTT4PUk/BPaIiK0tzLcDODwFrMuA59TKlt5VZ1q99FoB8yn/bprKcR5wHkB/f3/NPGZm1n4tBR1JC2qkERHLW5k/Ih6W9DNgDjBBUl9qzUwle5I1ZC2VacCgpD5gX2BzLr0iP0+9dDMz60Ktdq+9IPd6MXAm2d8d1CVpcmrhIGlP4JVkf399NfC6lG0hcHkaXpHGSdOviohI6Semu9sOBWYA1wM3ADPS3XC7kd1ssKLF7TEzsw5otXvt3flxSfsC32oy20HAsnSX2S7AJRHxQ0l3AhdJ+iRwE9nDREnv35K0lqyFc2Ja9x2SLgHuJPvjuCWp2w5J7wJWAuOACyLijla2x8zMOkNZY2KIM0m7ArdGRK1rNF2tv78/BgYGOl0MMxsFliyBc8+FxYvh7LM7XZr2kbQ6Ivqb52xhWa0EHUn/zs6L9LuQ/S7mkojouR9kOuiYWVH6+mDHDhg3DrZvb56/VxUZdBp2r0l6FnAg8K+55O1k3Vn3F1EAM7NetXjxzpaOtaZhSyfdHv2RiLi1Kr0fOCMijmtz+Qrnlo6Z2dAU2dJpdvfa9OqAAxARA8D0IgpgZmZjR7Ogs0eDaXsWWRAzM8guzvf1Ze82+jQLOjdIelt1oqRTgdXtKZKZjWXnnptdnD/33E6XxNqh2e903gtcJulkdgaZfmA34DXtLJiZjU2+OD+6tXrL9MuBmWn0joi4qq2laiPfSGBmNjSl3TJdERFXkz2+xszMbNhaffaamZnZiDnomJlZaRx0zMysNA46ZmZWGgcdMzMrjYOOmVmHjMWnLzjomFnbjcWTayvG4tMXHHTMrO3G4sm1FYsXZ//FM5aevuCgY2ZtNxZPrq04++zsz99G87+OVhvW31X3Mj8Gx8xsaMr8Px0zM7PCOOiYmVlpHHTMzKw0bQs6kqZJulrSXZLukPSelD5J0ipJa9L7xJQuSWdJWivpVkmzcstamPKvkbQwlz5b0m1pnrMkqV3bY2ZmI9fOls524P0R8RxgDrBE0mHAUuDKiJgBXJnGAY4BZqTXIuAcyIIUcAZwJHAEcEYlUKU8i3LzzWvj9piZ2Qi1LehExIaIuDENbwPuAqYA84FlKdsy4Pg0PB9YHplrgQmSDgKOBlZFxOaI2AKsAualaeMj4prIbsFbnltWXffd5x+pmZl1SinXdCRNB54PXAccGBEbIAtMwAEp2xRgfW62wZTWKH2wRnpDmzb5R2pmZp3S9qAjaW/ge8B7I+KRRllrpMUw0muVYZGkAUkDe+/9uH+kZmbWIW0NOpJ2JQs4F0bE91Pyg6lrjPS+MaUPAtNys08FHmiSPrVG+lNExHkR0R8R/c9+9p5j7hfAZmbdop13rwk4H7grIj6fm7QCqNyBthC4PJe+IN3FNgfYmrrfVgJzJU1MNxDMBVamadskzUnrWpBblpmZdaG+Ni77RcCbgNsk3ZzSPgJ8GrhE0qnAfcAJadqPgGOBtcBjwCkAEbFZ0ieAG1K+j0fE5jT8DuCbwJ7AFellZmZdys9eMzOzhvzsNTMz60kOOmZmVhoHHTMzK42DjpmZlcZBx8zMSuOgY2ZmpXHQMTOz0jjomJlZaRx0zMysNA46ZmZWGgcdMzMrjYOOmZmVxkHHzMxK46BjZmalcdAxM7PSOOiYmVlpHHTMzKw0DjpmZlYaBx0zMyuNg46ZmZXGQcfMzErjoGNmZqVx0DGzMWvJEujry96tHG0LOpIukLRR0u25tEmSVklak94npnRJOkvSWkm3SpqVm2dhyr9G0sJc+mxJt6V5zpKkdm2LmY1O554LO3Zk71aOdrZ0vgnMq0pbClwZETOAK9M4wDHAjPRaBJwDWZACzgCOBI4AzqgEqpRnUW6+6nWZmTW0eDGMG5e9WznaFnQi4hfA5qrk+cCyNLwMOD6Xvjwy1wITJB0EHA2siojNEbEFWAXMS9PGR8Q1ERHA8tyyzMxacvbZsH179m7lKPuazoERsQEgvR+Q0qcA63P5BlNao/TBGuk1SVokaUDSwKZNm0a8EWZmzfh6UW3dciNBresxMYz0miLivIjoj4j+yZMnD7OIZmat8/Wi2soOOg+mrjHS+8aUPghMy+WbCjzQJH1qjXQzs67g60W1lR10VgCVO9AWApfn0heku9jmAFtT99tKYK6kiekGgrnAyjRtm6Q56a61BbllmZl1XC9eLyqjS1DZdfg2LFj6N+BlwP7Ag2R3of0AuAQ4GLgPOCEiNqfA8WWyO9AeA06JiIG0nLcAH0mL/VREfCOl95PdIbcncAXw7mhhY/r7+2NgYKCgrTQzGz36+rIuwXHjsoBZIWl1RPQXso4iFlJLRJxUZ9JRNfIGUDO2RsQFwAU10geAmSMpo5mZ7bR4cXYNqp1dgm1r6XQrt3TMzIamyJZOt9y9ZmZmY4CDjo15/j1Fd/H+GN0cdGzM8+8pytFqMPH+GN0cdPA3q7HOv6coR6vBxPtjdPONBNS/TdCGb8mSnXfB9NLvFKx9fEz0Lt9IUDB/syqeu0isWi/+WNKK56BDb34Yur1L0IHcRqLbj28bPnev9Sh3CVo3aFeXmY/v7uLuNRvTLQl/C+4e7epGHcvH92jnoNOjerFLsCi+XtQ92hUczj575yNZ/OWiON3whc1Bx5rqxIHaaJ1Fn+i64YPYq/JffoquR3+5KF5X1GlEjKnX7Nmzw4Zm3LgIyN5H4zo7sX1Fe+c7s/K/852dK0PR9dgN25TXbeUZjuFuAzAQBZ2D3dLpEt38bbsT/etlrnM0XD/ohm+wRddjJ7qQG30Ou6GOqw31vNEV3fJFRa9eeXVrS6fIb4nV32Z66RtaL5W1W7zzndmxI7neRqrR57Abj82yWukU2NLpeBAo+9WtQafZAT2UA776QOyl7qNeKmu3GE111ukA2o2BpZGyyuugMwqDTjNDObGMhpbOzJm9U+ZOq3WirrXPizgO2n0sVY7zMoNor3w+OllOB52Sgk43HYzdVJahGk7ZR9O394p27sNWWrdF1Gm790s7WjrNvsiMdJvK+myW/ZnIb5eDTklBZzSe+DphOPXYy0G2nupv8UVuWyut2yJaP+1qQVUvq8iWbr7eax2HIy1/WXftlf2ZyG+Xg05JQafdO7kdH9ZuPEkP9UTSLR+6olW+xTfrPmplO4uqi25r/TQLEMPR7i7b/H6dOXPky8tvfye5pdPmoNOJANCOD+twT2RF3sgw3DJW54NsfZV1S63XV7cGqOptyxvKdhZx7OS7svIn5CJaP43SW1lWKwGim/ZxkYGisv+lkS+rKA46bQg6I7lQ3+qyirjAP9wTRfU3yPz8M2dG02+WteYf6oc9v55mJ5PqdTVbb/XJaigBarga1flwTsT5Oq5sZz5/ft9PmhRP+WY91OOpen35Oq+1n4a7/GZfhJoFmHrrbUf391C/fFXGa+2PosvQav0PdT9VPpeTJtWfz0FnJBvM7JoHRrOAkB9vdLDXamqPpFul3sm0+tUsCFR/i673avZhG0nXR/U1jVrblz+51nrl15mft17+VuulkqdZYKxMr5S3Xj0M54RYvR3VwbPWvssfk40Cbb5OK3XSaH3Vx0T1/LXqrtY+qVX/9Y7FfLlr7dPq7ap3sqwXqFs5CeeP0VrBMF/m6s9Dq1+khnuTRKNWcq18+WOj1rbU+kxXH1cVDjr5DYB5wK+BtcDS5vlnR3UTuNaBWW9n1Dux5U9CzV75oFfvw9XoRNro1ejD1uhkXn0g1zqhV58kZs6sHWSr67RWi6ryzbBW+Wud+PLLqGxjswDarO7z+3ln33XjeqleVvVJr/qbb61l1DtZDmU7dtml8X7J78NGJ5d8+fLbX13+6nVU112j46vRiTu//Hz91VpOdT23Uk+1Alt1cGrluGz1VWs/t3osVu+z/DKqP2v546+61yN/fA2l7JX6rQ6s2fJmR0Qx5+ye/j8dSeOA3wB/CwwCNwAnRcSd9efpD+j9/9MxMytPPxEDKmJJvf7stSOAtRFxT0Q8AVwEzO9wmczMrI6+ThdghKYA63Pjg8CR1ZkkLQIWZWP7AYX8AZ6Z2RixrrAl9XrQqdXce0p/YUScB5wHIGkg4vddHXWyMhbz17Dt0gtlhN4op8tYnF4o51gvY693rw0C03LjU4EHOlQWMzNroteDzg3ADEmHStoNOBFY0eEymZlZHT3dvRYR2yW9C1gJjAMuiIg7msx2XvtLNmIuY3F6oZwuY3F6oZxjuow9fcu0mZn1ll7vXjMzsx7ioGNmZqUZM0FH0jxJv5a0VtLSktc9TdLVku6SdIek96T0MyXdL+nm9Do2N8/pqay/lnR0WdshaZ2k21J5BlLaJEmrJK1J7xNTuiSdlcpyq6RZueUsTPnXSFpYYPmenauvmyU9Ium9na5LSRdI2ijp9lxaYfUmaXbaL2vTvMP6dXidcn5W0q9SWS6TNCGlT5f0eK5Ov9qsPPW2uYAyFrZ/ld14dF0q48XKbkIqoowX58q3TtLNKb1T9VjvvNPZ47Ko5+l084vsJoO7gWcAuwG3AIeVuP6DgFlpeB+yR/ccBpwJfKBG/sNSGXcHDk1lH1fGdpD9Cmz/qrR/IT3XDlgKfCYNHwtcQfZ7qTnAdSl9EnBPep+Yhie2ab/+Djik03UJvASYBdzejnoDrgdemOa5AjimwHLOBfrS8Gdy5Zyez1e1nJrlqbfNBZSxsP0LXAKcmIa/CryjiDJWTf8c8I8drsd6552OHpdjpaXT0cflRMSGiLgxDW8D7iJ7mkI984GLIuKPEXEv2cNMj6Bz2zEfWJaGlwHH59KXR+ZaYIKkg4CjgVURsTkitgCryB7MWrSjgLsj4rdNyt72uoyIXwCba6x7xPWWpo2PiGsi+6Qvzy1rxOWMiJ9ExPY0ei3Z793qalKeets8ojI2MKT9m76JvwL4brvKmNbxeuDfGi2jhHqsd97p6HE5VoJOrcflNDrpt42k6cBOUxcCAAAE30lEQVTzgetS0rtSU/aCXBO6XnnL2I4AfiJptbLHBwEcGBEbIDuQgQO6oJyQ/S4r/8Hutrosqt6mpOF2lrXiLWTfWCsOlXSTpJ9LenFKa1SeettchCL2737Aw7kg2466fDHwYESsyaV1tB6rzjsdPS7HStBp6XE5bS+EtDfwPeC9EfEIcA7wTOBwYANZkxzql7eM7XhRRMwCjgGWSHpJg7wdK2fqh381cGlK6sa6rGeoZSqlrJI+CmwHLkxJG4CDI+L5wPuA70gaX1Z5qhS1f8so+0k8+ctQR+uxxnmnbtY65Sm0LsdK0On443Ik7Uq24y+MiO8DRMSDEbEjIv4MfI2sS6BRedu+HRHxQHrfCFyWyvRgakpXugQ2drqcZEHxxoh4MJW36+qS4uptkCd3eRVe1nRx+O+Ak1NXCanL6qE0vJrsGslfNSlPvW0ekQL37+/Juo36qtILkZb7P4CLc2XvWD3WOu80WHYpx+VYCTodfVxO6uM9H7grIj6fSz8ol+01QOVOmBXAiZJ2l3QoMIPsgl1bt0PSXpL2qQyTXWC+Pa2jcsfKQuDyXDkXpLte5gBbU3N9JTBX0sTUDTI3pRXpSd8mu60uc+secb2ladskzUnH0oLcskZM0jzgw8CrI+KxXPpkZf9ZhaRnkNXdPU3KU2+bR1rGQvZvCqhXA68ruozJK4FfRcRfup06VY/1zjsNll3OcdnsToPR8iK7M+M3ZN8yPlryuv87WbPzVuDm9DoW+BZwW0pfARyUm+ejqay/JndHSDu3g+xOn1vS647K8sn6wa8E1qT3SSldwNmpLLcB/bllvYXsou5a4JSCy/k04CFg31xaR+uSLABuAP5E9g3w1CLrjez/OG5P83yZ9DSRgsq5lqzPvnJsfjXlfW06Dm4BbgSOa1aeettcQBkL27/pOL8+bfelwO5FlDGlfxN4e1XeTtVjvfNOR49LPwbHzMxKM1a618zMrAs46JiZWWkcdMzMrDQOOmZmVhoHHTMzK42DjtkwSdqh7KnBt0u6VNLTmuRfJ2n/Jnn+UGwpzbqLg47Z8D0eEYdHxEzgCeDtZaw092t6s57joGNWjP8AngUg6Qfpgal35B6a+iSN8kj6nKQbJV0paXJK+5mkf5L0c+A9ko5T9p8wN0n6qaQDU76Xauf/ttxUecKEWbdw0DEbodTyOIbsV9wAb4mI2WS/1j5N0n41ZquXZy+yZ8rNAn4OnJGbZ0JEvDQiPgf8JzAnsodIXgR8KOX5ALAkIg4ne9rx44VtqFkB3Ew3G749lf4dkqylc34aPk3Sa9LwNLJnbT1UNW+9PH9m58Mivw18PzfPxbnhqcDF6ZlkuwH3pvRfAp+XdCHw/cg9A8ysG7ilYzZ8lWs6h0fEuyPiCUkvI3vo4wsj4nnATcAe+ZlayZOTf07Vo7nhLwFfjoi/ARZX5o+ITwNvBfYErpX01yPcRrNCOeiYFWtfYEtEPJZO+HOGmGcXdj4B+Y1k3Wj11nN/Gs7/Z/0zI+K2iPgMMAA46FhXcfeaWbF+DLxd0q1kTz2+doh5HgWeK2k1sBV4Q531nAlcKun+NP+hKf29kl4O7ADu5Mn/AmrWcX7KtJmZlcbda2ZmVhoHHTMzK42DjpmZlcZBx8zMSuOgY2ZmpXHQMTOz0jjomJlZaf4/3NvgypPeyEMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cinco palabras que más aparecen ['the', 'in', 'of', 'to', 'a']\n"
     ]
    }
   ],
   "source": [
    "dictWord = numberWord()\n",
    "graphWordDes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zipf():\n",
    "    word = list(dictWord.values())\n",
    "    total = wordCo\n",
    "    frec = []\n",
    "    for i in range(len(word)):\n",
    "        temp = word[i]/total\n",
    "        frec.append(temp*100)\n",
    "    plt.plot((frec)*100,'go', markersize=2)\n",
    "    plt.axis([0, len(word), 0, max(frec)*1.04])\n",
    "    plt.ylabel('%')\n",
    "    plt.xlabel('Palabras')\n",
    "    plt.title('Frecuencia de las palabras')\n",
    "    plt.show()\n",
    "    print('Cinco mayor % :',nlargest(5, frec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cinco mayor % : [6.115422169690118, 2.6634348002352524, 2.5144035036629724, 2.2321386086224977, 2.1790355029473174]\n"
     ]
    }
   ],
   "source": [
    "zipf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> No se observa una ley de Zipf porque la ley dice que la segunda palabra tiene que tener una frecuencia de 1/2 de la primera, la terceira 1/3 asin hasta la ultima, y como pudemos mirar las frequencias no tiene ese estandar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TagCounter():\n",
    "    words = newDataY\n",
    "    counts = {}\n",
    "    for word in words:\n",
    "        if word not in counts:\n",
    "            counts[word] = 0\n",
    "        counts[word] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagGraph():\n",
    "    temp = tagSp\n",
    "    plt.plot(list(temp.values()),'co', markersize=8)\n",
    "    plt.axis([0, len(temp), 0, max(temp.values())*1.07])\n",
    "    plt.ylabel('Cuantidad')\n",
    "    plt.xlabel('Tags')\n",
    "    plt.show()\n",
    "    values = list(temp.values())\n",
    "    keys = list(temp.keys())\n",
    "    for i in range(len(keys)):\n",
    "        print(keys[i], '=', values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-per = 17011\n",
      "B-nat = 226\n",
      "I-gpe = 229\n",
      "I-eve = 297\n",
      "I-geo = 7409\n",
      "I-per = 17382\n",
      "I-nat = 76\n",
      "O = 889966\n",
      "B-tim = 20193\n",
      "I-org = 16537\n",
      "B-org = 20184\n",
      "I-tim = 6298\n",
      "B-gpe = 16391\n",
      "B-geo = 37525\n",
      "B-art = 434\n",
      "B-eve = 348\n",
      "I-art = 280\n"
     ]
    }
   ],
   "source": [
    "tagSp = TagCounter()\n",
    "tagGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> La distrubuicion de palabra sin Tag (O) es lka mayor porque esas palabras san las pababras conectivas como: the, of, in.\n",
    "Entonces eso es un resultado esperado.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Nota: </b>\n",
    "    \n",
    "geo = Entidad Geográfica\n",
    "\n",
    "org = Organización\n",
    "\n",
    "per = persona\n",
    "\n",
    "gpe = entidad geopolítica\n",
    "\n",
    "tim = indicador de tiempo\n",
    "\n",
    "arte = artefacto\n",
    "\n",
    "eve = Evento\n",
    "\n",
    "nat = Fenómeno Natural\n",
    "\n",
    "O = Nada\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pregunta C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 20243\n"
     ]
    }
   ],
   "source": [
    "lemma2idx = {w: i for i, w in enumerate(wordSp)}\n",
    "lab2idx = {t: i for i, t in enumerate(tagSp)}\n",
    "numberDataX = [[lemma2idx[lemma] for lemma in sentence ] for sentence in dataX]\n",
    "numberDataY = [[lab2idx[ner] for ner in ner_tags ] for ner_tags in dataY]\n",
    "n_lemmas = len(wordSp)\n",
    "n_labels = len(tagSp)\n",
    "print(n_labels,n_lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Los valores estan corectos porque es la misma cuantidad de palabra y de tags en lo dataset original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pregunta D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_lenght = max(arrayNum)\n",
    "Xpost = sequence.pad_sequences(numberDataX, maxlen=max_input_lenght, padding='post',value=0)\n",
    "Ypost = sequence.pad_sequences(numberDataY ,maxlen=max_input_lenght, padding='post',value=0)\n",
    "Xpre = sequence.pad_sequences(numberDataX, maxlen=max_input_lenght, padding='pre',value=0)\n",
    "Ypre = sequence.pad_sequences(numberDataY ,maxlen=max_input_lenght, padding='pre',value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los datos de X post\n",
      " [ 6478 14182  9894  3112 18854 17570  8756 17733 17423 14538  6237 16824\n",
      "  2217    85 16784 14538   723 14182  4005 14108 14287   422 12650 12040\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0] \n",
      "\n",
      "\n",
      "Los datos de Y post\n",
      " [ 7  7  7  7  7  7 13  7  7  7  7  7 13  7  7  7  7  7 12  7  7  7  7  7\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0] \n",
      "\n",
      "\n",
      "Los datos de X pr\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0  6478 14182  9894\n",
      "  3112 18854 17570  8756 17733 17423 14538  6237 16824  2217    85 16784\n",
      " 14538   723 14182  4005 14108 14287   422 12650 12040] \n",
      "\n",
      "\n",
      "Los datos de Y pre\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  7  7  7  7  7  7 13  7  7  7  7  7 13  7  7\n",
      "  7  7  7 12  7  7  7  7  7]\n"
     ]
    }
   ],
   "source": [
    "print('Los datos de X post\\n',Xpost[0],'\\n\\n\\nLos datos de Y post\\n',Ypost[0],'\\n\\n\\nLos datos de X pre\\n',Xpre[0],'\\n\\n\\nLos datos de Y pre\\n',Ypre[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Al pricinpio dela sentencia porque asin se la red no tendrá ningum problema con su aprendizaje\n",
    "\n",
    "##### Pregunta E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.asarray([to_categorical(i, num_classes=n_labels) for i in Ypost])\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xpost, Ypost, test_size=0.3,random_state=22)\n",
    "y_train= keras.utils.to_categorical(y_train,num_classes=17)\n",
    "y_test = keras.utils.to_categorical(y_test,num_classes=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33656 14425 33656 14425\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train),len(X_test),len(y_train),len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Los vectores de entrada (X_train y y_train) tienen una dimension de 33656 que es 70% del datos de input (Xpost y Ypost) y los datos X_test y y_test tienen lo tamaño que queda del datos\n",
    "\n",
    "##### Pregunta F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    embedding_vector = x\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=n_lemmas, output_dim=embedding_vector, input_length=max_input_lenght))\n",
    "    model.add(LSTM(units=100,return_sequences=True))\n",
    "    model.add(Dense(n_labels, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=128)\n",
    "    a = model.predict_classes(X_test,verbose=0)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 81, 32)            647776    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 81, 100)           53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 81, 17)            1717      \n",
      "=================================================================\n",
      "Total params: 702,693\n",
      "Trainable params: 702,693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 33656 samples, validate on 14425 samples\n",
      "Epoch 1/3\n",
      "33656/33656 [==============================] - 49s 1ms/step - loss: 0.4999 - val_loss: 0.2155\n",
      "Epoch 2/3\n",
      "33656/33656 [==============================] - 47s 1ms/step - loss: 0.1615 - val_loss: 0.1167\n",
      "Epoch 3/3\n",
      "33656/33656 [==============================] - 47s 1ms/step - loss: 0.0967 - val_loss: 0.0831\n"
     ]
    }
   ],
   "source": [
    "modelF = model(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertY():\n",
    "    new_y_test = []\n",
    "    for i in range(len(y_test)):\n",
    "        for k in range(len(y_test[i])):\n",
    "            for j in range(len(y_test[i][k])):\n",
    "                if y_test[i][k][j] > 0:\n",
    "                    new_y_test.append(j)\n",
    "    return new_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y_test = convertY()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    model = [item for sublist in x for item in sublist]\n",
    "    print(classification_metrics.type_of_target(new_y_test))\n",
    "    print(classification_metrics.type_of_target(model))\n",
    "    print(len(model),len(new_y_test))\n",
    "    print(\"F1 score on test: \", f1_score(new_y_test, model,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiclass\n",
      "multiclass\n",
      "1168425 1168425\n",
      "F1 score on test:  0.31243541930394997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christian\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "predict(modelF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Cuando los datos entran en la red pasan por tres 'Gates', Keep Gate, Read Gate y Write Gate.\n",
    "Write Gate es responsable de escribir los datos en la memoria.\n",
    "Read Gate lee los datos de la memoria y envía los datos de nuevo a la red recurrente\n",
    "Keep Gate es reponible por mantener o borrar datos de la memoria\n",
    "\n",
    "<img src=\"LSTM.png\" title=\"Title text\" width=\"80%\" height=\"50%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pregunta G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 81, 16)            323888    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 81, 100)           46800     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 81, 17)            1717      \n",
      "=================================================================\n",
      "Total params: 372,405\n",
      "Trainable params: 372,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 33656 samples, validate on 14425 samples\n",
      "Epoch 1/3\n",
      "33656/33656 [==============================] - 48s 1ms/step - loss: 0.5096 - val_loss: 0.2286\n",
      "Epoch 2/3\n",
      "33656/33656 [==============================] - 46s 1ms/step - loss: 0.1873 - val_loss: 0.1400\n",
      "Epoch 3/3\n",
      "33656/33656 [==============================] - 46s 1ms/step - loss: 0.1140 - val_loss: 0.0978\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 81, 64)            1295552   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 81, 100)           66000     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 81, 17)            1717      \n",
      "=================================================================\n",
      "Total params: 1,363,269\n",
      "Trainable params: 1,363,269\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 33656 samples, validate on 14425 samples\n",
      "Epoch 1/3\n",
      "33656/33656 [==============================] - 48s 1ms/step - loss: 0.4528 - val_loss: 0.1902\n",
      "Epoch 2/3\n",
      "33656/33656 [==============================] - 47s 1ms/step - loss: 0.1332 - val_loss: 0.1013\n",
      "Epoch 3/3\n",
      "33656/33656 [==============================] - 47s 1ms/step - loss: 0.0827 - val_loss: 0.0693\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 81, 128)           2591104   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 81, 100)           91600     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 81, 17)            1717      \n",
      "=================================================================\n",
      "Total params: 2,684,421\n",
      "Trainable params: 2,684,421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 33656 samples, validate on 14425 samples\n",
      "Epoch 1/3\n",
      "33656/33656 [==============================] - 49s 1ms/step - loss: 0.4144 - val_loss: 0.1427\n",
      "Epoch 2/3\n",
      "33656/33656 [==============================] - 47s 1ms/step - loss: 0.1037 - val_loss: 0.0799\n",
      "Epoch 3/3\n",
      "33656/33656 [==============================] - 47s 1ms/step - loss: 0.0621 - val_loss: 0.0557\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 81, 256)           5182208   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 81, 100)           142800    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 81, 17)            1717      \n",
      "=================================================================\n",
      "Total params: 5,326,725\n",
      "Trainable params: 5,326,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 33656 samples, validate on 14425 samples\n",
      "Epoch 1/3\n",
      "33656/33656 [==============================] - 51s 2ms/step - loss: 0.3448 - val_loss: 0.1161\n",
      "Epoch 2/3\n",
      "33656/33656 [==============================] - 49s 1ms/step - loss: 0.0859 - val_loss: 0.0643\n",
      "Epoch 3/3\n",
      "33656/33656 [==============================] - 49s 1ms/step - loss: 0.0509 - val_loss: 0.0485\n"
     ]
    }
   ],
   "source": [
    "modelG_16 = model(16)\n",
    "modelG_64 = model(64)\n",
    "modelG_128 = model(128)\n",
    "modelG_256 = model(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiclass\n",
      "multiclass\n",
      "1168425 1168425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christian\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on test:  0.22519733520548413\n",
      "multiclass\n",
      "multiclass\n",
      "1168425 1168425\n",
      "F1 score on test:  0.40584275010311244\n",
      "multiclass\n",
      "multiclass\n",
      "1168425 1168425\n",
      "F1 score on test:  0.4526006968179854\n",
      "multiclass\n",
      "multiclass\n",
      "1168425 1168425\n",
      "F1 score on test:  0.46699748869717195\n"
     ]
    }
   ],
   "source": [
    "predict(modelG_16)\n",
    "predict(modelG_64)\n",
    "predict(modelG_128)\n",
    "predict(modelG_256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Al aumentar el valor de embedding el error aumentó pero al usar un embedding menor el error cayó considerablemente. No fue algo esperado porque en la tarea 2 ejercicio 3 al almentar el embedding el resultado mejoraba, pero creo que como la cantidad de datos disponibles para entrenar en este ejercicio y el MSE es mucho menor la probable causa del hecho de menores embedding ser mejores es el Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pregunta H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelDrop(x):\n",
    "    embedding_vector = x\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=n_lemmas, output_dim=embedding_vector, input_length=max_input_lenght))  \n",
    "    model.add(LSTM(units=100,return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(n_labels, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=128)\n",
    "    a = model.predict_classes(X_test,verbose=0)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33656 samples, validate on 14425 samples\n",
      "Epoch 1/3\n",
      "33656/33656 [==============================] - 49s 1ms/step - loss: 0.5342 - val_loss: 0.2328\n",
      "Epoch 2/3\n",
      "33656/33656 [==============================] - 47s 1ms/step - loss: 0.1980 - val_loss: 0.1503\n",
      "Epoch 3/3\n",
      "33656/33656 [==============================] - 47s 1ms/step - loss: 0.1241 - val_loss: 0.1034\n"
     ]
    }
   ],
   "source": [
    "modelDrop = modelDrop(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiclass\n",
      "multiclass\n",
      "1168425 1168425\n",
      "F1 score on test:  0.2178524239169408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christian\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "predict(modelDrop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> El Dropout mejora mucho el funcionamiento de la red, porque como dicho en el ejercicio anterio probablemente esta teniendo Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pregunta I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelI(x,y):\n",
    "    y = str(y)\n",
    "    merge = {'1':'sum','2':'mul','3':'ave','4':'concat'}\n",
    "    label = y\n",
    "    embedding_vector = x\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=n_lemmas, output_dim=embedding_vector, input_length=max_input_lenght))\n",
    "    layer_lstm = LSTM(units=100,return_sequences=True)\n",
    "    model.add(Bidirectional(layer_lstm,merge_mode=merge[y]))\n",
    "    model.add(Dense(n_labels, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=128)\n",
    "    a = model.predict_classes(X_test,verbose=0)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 81, 16)            323888    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 81, 100)           93600     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 81, 17)            1717      \n",
      "=================================================================\n",
      "Total params: 419,205\n",
      "Trainable params: 419,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 33656 samples, validate on 14425 samples\n",
      "Epoch 1/3\n",
      "33656/33656 [==============================] - 75s 2ms/step - loss: 0.3969 - val_loss: 0.2083\n",
      "Epoch 2/3\n",
      "33656/33656 [==============================] - 73s 2ms/step - loss: 0.1661 - val_loss: 0.1182\n",
      "Epoch 3/3\n",
      "33656/33656 [==============================] - 74s 2ms/step - loss: 0.0976 - val_loss: 0.0823\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 81, 16)            323888    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 81, 100)           93600     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 81, 17)            1717      \n",
      "=================================================================\n",
      "Total params: 419,205\n",
      "Trainable params: 419,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 33656 samples, validate on 14425 samples\n",
      "Epoch 1/3\n",
      "33656/33656 [==============================] - 74s 2ms/step - loss: 0.6079 - val_loss: 0.2376\n",
      "Epoch 2/3\n",
      "33656/33656 [==============================] - 72s 2ms/step - loss: 0.1879 - val_loss: 0.1321\n",
      "Epoch 3/3\n",
      "33656/33656 [==============================] - 72s 2ms/step - loss: 0.1034 - val_loss: 0.0871\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 81, 16)            323888    \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 81, 100)           93600     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 81, 17)            1717      \n",
      "=================================================================\n",
      "Total params: 419,205\n",
      "Trainable params: 419,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 33656 samples, validate on 14425 samples\n",
      "Epoch 1/3\n",
      "33656/33656 [==============================] - 74s 2ms/step - loss: 0.4565 - val_loss: 0.2154\n",
      "Epoch 2/3\n",
      "33656/33656 [==============================] - 72s 2ms/step - loss: 0.2027 - val_loss: 0.1818\n",
      "Epoch 3/3\n",
      "33656/33656 [==============================] - 71s 2ms/step - loss: 0.1401 - val_loss: 0.1082\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 81, 16)            323888    \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 81, 200)           93600     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 81, 17)            3417      \n",
      "=================================================================\n",
      "Total params: 420,905\n",
      "Trainable params: 420,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 33656 samples, validate on 14425 samples\n",
      "Epoch 1/3\n",
      "33656/33656 [==============================] - 74s 2ms/step - loss: 0.4151 - val_loss: 0.2091\n",
      "Epoch 2/3\n",
      "33656/33656 [==============================] - 72s 2ms/step - loss: 0.1916 - val_loss: 0.1528\n",
      "Epoch 3/3\n",
      "33656/33656 [==============================] - 72s 2ms/step - loss: 0.1099 - val_loss: 0.0876\n"
     ]
    }
   ],
   "source": [
    "modelI_1 = modelI(16,1)\n",
    "modelI_2 = modelI(16,2)\n",
    "modelI_3 = modelI(16,3)\n",
    "modelI_4 = modelI(16,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiclass\n",
      "multiclass\n",
      "1168425 1168425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christian\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on test:  0.2927976183001243\n",
      "multiclass\n",
      "multiclass\n",
      "1168425 1168425\n",
      "F1 score on test:  0.29112603426860095\n",
      "multiclass\n",
      "multiclass\n",
      "1168425 1168425\n",
      "F1 score on test:  0.1733218306526744\n",
      "multiclass\n",
      "multiclass\n",
      "1168425 1168425\n",
      "F1 score on test:  0.26737292170133875\n"
     ]
    }
   ],
   "source": [
    "predict(modelI_1)\n",
    "predict(modelI_2)\n",
    "predict(modelI_3)\n",
    "predict(modelI_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> El merge_mode de media presentó resultados mucho mejores que los otros probados y también mejora el desempeña de la red considerablemente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pregunta J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelJ(x):\n",
    "    embedding_vector = x\n",
    "    lemma2idx[\"yourspecialcharacter\"] = 0 \n",
    "    embedding_vector = 32\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=n_lemmas, output_dim=embedding_vector, input_length=max_input_lenght,mask_zero=True))\n",
    "    model.add(Dense(n_labels, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=128)\n",
    "    a = model.predict_classes(X_test,verbose=0)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 81, 32)            647776    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 81, 17)            561       \n",
      "=================================================================\n",
      "Total params: 648,337\n",
      "Trainable params: 648,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 33656 samples, validate on 14425 samples\n",
      "Epoch 1/3\n",
      "33656/33656 [==============================] - 3s 90us/step - loss: 1.5404 - val_loss: 0.5887\n",
      "Epoch 2/3\n",
      "33656/33656 [==============================] - 1s 43us/step - loss: 0.4416 - val_loss: 0.3583\n",
      "Epoch 3/3\n",
      "33656/33656 [==============================] - 1s 43us/step - loss: 0.3074 - val_loss: 0.2892\n"
     ]
    }
   ],
   "source": [
    "modelJ = modelJ(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiclass\n",
      "multiclass\n",
      "1168425 1168425\n",
      "F1 score on test:  0.33226310254598124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christian\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "predict(modelJ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> El entrenamiento ocurrió con un error mayor al comienzo, y el tiempo de entrenamiento tuvo una variación considerable, pero el error aumentó considerablemente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pregunta K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelK(x,y,w):\n",
    "    embedding_vector = x \n",
    "    y = str(y)\n",
    "    merge = {'1':'sum','2':'mul','3':'ave','4':'concat'}\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=n_lemmas, output_dim=embedding_vector, input_length=max_input_lenght))\n",
    "    layer_lstm = LSTM(units=100,return_sequences=True)\n",
    "    model.add(Bidirectional(layer_lstm,merge_mode=merge[y]))\n",
    "    model.add(Dropout(w))\n",
    "    model.add(Dense(n_labels, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=128)\n",
    "    a = model.predict_classes(X_test,verbose=0)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 81, 16)            323888    \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 81, 100)           93600     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 81, 100)           0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 81, 17)            1717      \n",
      "=================================================================\n",
      "Total params: 419,205\n",
      "Trainable params: 419,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 33656 samples, validate on 14425 samples\n",
      "Epoch 1/3\n",
      "33656/33656 [==============================] - 75s 2ms/step - loss: 0.4413 - val_loss: 0.2178\n",
      "Epoch 2/3\n",
      "33656/33656 [==============================] - 72s 2ms/step - loss: 0.2128 - val_loss: 0.2004\n",
      "Epoch 3/3\n",
      "33656/33656 [==============================] - 72s 2ms/step - loss: 0.1787 - val_loss: 0.1327\n"
     ]
    }
   ],
   "source": [
    "modelK_1 = modelK(16,3,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiclass\n",
      "multiclass\n",
      "1168425 1168425\n",
      "F1 score on test:  0.1306361169220866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christian\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "predict(modelK_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pregunta L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelJ(x,y,w):\n",
    "    embedding_vector = x \n",
    "    y = str(y)\n",
    "    merge = {'1':'sum','2':'mul','3':'ave','4':'concat'}\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=n_lemmas, output_dim=embedding_vector, input_length=max_input_lenght))\n",
    "    layer_lstm = LSTM(units=100,return_sequences=True)\n",
    "    model.add(Bidirectional(layer_lstm,merge_mode=merge[y]))\n",
    "    model.add(Dropout(w))\n",
    "    model.add(Dense(n_labels, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=128)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 81, 16)            323888    \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 81, 100)           93600     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 81, 100)           0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 81, 17)            1717      \n",
      "=================================================================\n",
      "Total params: 419,205\n",
      "Trainable params: 419,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 33656 samples, validate on 14425 samples\n",
      "Epoch 1/3\n",
      "33656/33656 [==============================] - 76s 2ms/step - loss: 0.4473 - val_loss: 0.2170\n",
      "Epoch 2/3\n",
      "33656/33656 [==============================] - 72s 2ms/step - loss: 0.2114 - val_loss: 0.1977\n",
      "Epoch 3/3\n",
      "33656/33656 [==============================] - 72s 2ms/step - loss: 0.1760 - val_loss: 0.1325\n"
     ]
    }
   ],
   "source": [
    "p = modelJ(16,3,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelJfit(x,y):\n",
    "    model = x\n",
    "    i = y\n",
    "    p = model.predict(np.array([X_test[i]]))\n",
    "    p = np.argmax(p, axis=-1)\n",
    "    print(\"{:15}: {}\".format(\"Lemma\", \"Pred\"))\n",
    "    for w,pred in zip(X_test[i],p[0]):\n",
    "        if w != 0:\n",
    "            print(\"{:15}: {}\".format(wordSp[w],list(tagSp.keys())[pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma          : Pred\n",
      "doctor         : O\n",
      "have           : O\n",
      "previous       : O\n",
      "said           : O\n",
      "that           : O\n",
      "mr.            : B-geo\n",
      "singh          : O\n",
      ",              : O\n",
      "who            : O\n",
      "is             : O\n",
      "76             : O\n",
      ",              : O\n",
      "should         : O\n",
      "be             : O\n",
      "abl            : O\n",
      "to             : O\n",
      "resum          : O\n",
      "his            : O\n",
      "full           : O\n",
      "duti           : O\n",
      "within         : O\n",
      "four           : O\n",
      "week           : O\n",
      ".              : O\n"
     ]
    }
   ],
   "source": [
    "modelJfit(p, random.randint(0, len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> En el caso de que la red no esta generando las Pred con mucha precisión pero esto puede ser explicado por el hecho de Tag 'O' tener un porcentaje mucho mayor de lo que las otras etiquetas y tal vez al encontrar otro ejemplo la red demuestre otras Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pregunta M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 72\n",
      "nb sequences: 303368\n"
     ]
    }
   ],
   "source": [
    "dataset = df_ner.loc[:,[\"word\",\"lemma\"]]\n",
    "text = ' '.join(dataset[\"word\"]).lower() \n",
    "null_character = \"*\"\n",
    "chars = [null_character]+sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = {c: i for i, c in enumerate(chars)}\n",
    "indices_char = {i: c for i, c in enumerate(chars)}\n",
    "maxlen = 40 \n",
    "step = 5 \n",
    "sentences = []\n",
    "next_chars = []\n",
    "size = int(len(text)*0.25)\n",
    "for i in range(0, size - maxlen, step):\n",
    "    sentences.append(null_character+text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Se debe usa 'word' porque los verbos tienen tiempos verbales diferentes del presente y los tiempos verbales tiene grand peso en la seguinte palabra\n",
    "\n",
    "##### Pregunta N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX = [[char_indices[char] for char in sentence ] for sentence in sentences]\n",
    "dataY = [char_indices[char] for char in next_chars]\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(dataX, dataY, test_size=0.3,random_state=22)\n",
    "X_test_2 = sequence.pad_sequences(dataX, maxlen=41, padding='pre',value=0)\n",
    "X_train_2 = sequence.pad_sequences(dataX, maxlen=41, padding='pre',value=0)\n",
    "y_test_2 = keras.utils.to_categorical(dataY,num_classes=72)\n",
    "y_train_2 = keras.utils.to_categorical(dataY,num_classes=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelCuD():\n",
    "    embedding_vector = 16\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len(chars), output_dim=embedding_vector, input_length=maxlen+1))\n",
    "    model.add(CuDNNGRU(units=512,return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(len(chars), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelGru():\n",
    "    embedding_vector = 16\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len(chars), output_dim=embedding_vector, input_length=maxlen+1))\n",
    "    model.add(GRU(units=512,return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(len(chars), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pregunta O (GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_char(model, sentence):   \n",
    "    x_pred = [char_indices[null_character]]+[char_indices[char] for char in sentence]\n",
    "    x_pred = sequence.pad_sequences([x_pred], maxlen=maxlen+1,padding='pre',value=char_indices[null_character])\n",
    "    preds = model.predict(x_pred, verbose=0)[0]\n",
    "    next_index = np.random.choice(len(chars), p=preds)\n",
    "    return indices_char[next_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, logs):\n",
    "    print('\\n----- Generating text after Epoch: %d' % epoch)\n",
    "    start_index = random.randint(0, size - maxlen - 1)\n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(sentence)\n",
    "    for i in range(400):\n",
    "        next_char = predict_next_char(modGru, sentence)\n",
    "        sentence = sentence[1:] + next_char\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "modGru = modelGru()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "303368/303368 [==============================] - 106s 349us/step - loss: 2.4867 - acc: 0.2857s \n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- Generating with seed: \"pportunity to do so . general dostum 's \"\n",
      "pportunity to do so . general dostum 's oun caested than semun in heacend onfaticalintal exce redes , pun and emrocedind noplavian cepanulel and wigl choed e besmine of visintistinkian-line offecisesudel temriwiek coaml brore to klins sand makled the ruthir themel wos hagwed bland in negher of beke won lalacust atrialed ty hemergcen comnamed agpants in porithan oobe , the politident . ches cold lfremen day abdiocubey . bel atoret woveinEpoch 2/25\n",
      "303368/303368 [==============================] - 104s 342us/step - loss: 1.8910 - acc: 0.4427\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- Generating with seed: \"ticipate in the july elections . palesti\"\n",
      "ticipate in the july elections . palestirited ropolicit fus sorianina in a security ferped a tareb joteld the bopne , prico , the for nawing intestar e the dexord e2vonger of mings millim nom .t tuindal joudi ald with into the chpresfory suffs two , censoul mee.nta thut oreh afteb the coules mengoned on tounctarated tay firlar pericinistart . in uministar y in the pro-reactrolly the ciaring to dombanded lele , gargal not fos abaup also Epoch 3/25\n",
      "303368/303368 [==============================] - 104s 342us/step - loss: 1.6133 - acc: 0.5257\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "----- Generating with seed: \"ith a smaller rebel group and rightist p\"\n",
      "ith a smaller rebel group and rightist presidentiamens exicuntly taken se, sade hiw in indratial ald wsing of the abrodict conglane in eerplamed in the and cape-a for tilet four entired world in the eriopth , masy roupli wead hhar . difporting list menth talebon is the unity . mr. nasuss wat marlies have thees wo-ld this weeks of thencratus and fores of four in said tee ve taleban seazro \" but iraqi . sayerssued arto and war in luast onEpoch 4/25\n",
      "303368/303368 [==============================] - 104s 342us/step - loss: 1.4560 - acc: 0.5694s - loss: 1.4559 - acc: 0.5\n",
      "\n",
      "----- Generating text after Epoch: 3\n",
      "----- Generating with seed: \"sound trading environment for economic g\"\n",
      "sound trading environment for economic government and other derates tranefoum with drhanged near the threu-uth signed exterdier national for for the global year to developing a stobm president bush reports rate for the works of the repanes on the wet e conened there day not an in iraq , mador a resufters outsade ( 27 of jet top , to diddive redicions . \" an and atraeti in rase a emecged to veatingacy the verezue tome montas , the readerEpoch 5/25\n",
      "303368/303368 [==============================] - 104s 341us/step - loss: 1.3464 - acc: 0.5999\n",
      "\n",
      "----- Generating text after Epoch: 4\n",
      "----- Generating with seed: \"nified command of nato . the un security\"\n",
      "nified command of nato . the un security leader says mr.  hinder foreign bomb jounnalitters in ubanize moye were stated posses investigation enfor firm. says this minist y the oldmri dear burankilli , the united ntates hostroguted the hes fiohter to must to trust wasts the attack on dusing mexico . energy and new dors-n-tienditate said ctalstan of sudanese protest-lisching it last 2500 . the both remeess , net sate must in the missiles Epoch 6/25\n",
      "303368/303368 [==============================] - 103s 341us/step - loss: 1.2617 - acc: 0.6225\n",
      "\n",
      "----- Generating text after Epoch: 5\n",
      "----- Generating with seed: \"e runway during landing and crashed , sp\"\n",
      "e runway during landing and crashed , spokesman dlovult on the vote charge sharous allegations of poscess in satallater . president bush ach over the cerelon from authorities in saturday 's attack . shows and notembly killed by the military because lo spetoon7 . vileace for discusside in sobviews that barrel viclons in the early 2003 . sebon when the capital for the the duct is imbegifainaits in a condelnator in a bild lint . taleban miEpoch 7/25\n",
      "303368/303368 [==============================] - 104s 342us/step - loss: 1.1941 - acc: 0.6414s - loss: 1.1940 - acc: 0.64\n",
      "\n",
      "----- Generating text after Epoch: 6\n",
      "----- Generating with seed: \"ilitary personnel killed in battle . the\"\n",
      "ilitary personnel killed in battle . the attack in jumply by , sedicto hadsered held septedden to face to nationally century have decaded the town of a plane closer the houlling force dyangers . whiys too where te police theen opposition century . afthan that to man gaiper and stembullate out muka muslims of the region . next plot , kning hheliver . mashints to dives flugion dirict world recup for in juby 11 people over mole to annourceEpoch 8/25\n",
      "303368/303368 [==============================] - 103s 341us/step - loss: 1.1335 - acc: 0.6580s - los\n",
      "\n",
      "----- Generating text after Epoch: 7\n",
      "----- Generating with seed: \"he money will be used to provide both re\"\n",
      "he money will be used to provide both reauls now hit haj ugund u.s. latesp representatively afral than dozmikal , a what he says him , which ended in suckid : 20,200 ) as willlind of the wounded as second khos hamas for moverned to cartion by nusterrance , including a wordeg in the u.s. -bost 67 members had been deadlies . sing and palts at the leader 's out bereary 's president a scine a recards . protest ocleamer 's survay tead is theEpoch 9/25\n",
      "303368/303368 [==============================] - 104s 341us/step - loss: 1.0854 - acc: 0.6700\n",
      "\n",
      "----- Generating text after Epoch: 8\n",
      "----- Generating with seed: \"20-ton capsule by 2015 . a first launch \"\n",
      "20-ton capsule by 2015 . a first launch said filling sunday to adtaspates in judgi . the buildings in the one car bilint more and not . taggets flood in septembord 30 % of those  cun militants in since the palestinian negbon-200 commissed resurreges in baghdad follow rebels age tional wiongres shoups a review . it will be  . ministnop has speckorly deld aces said bigan inleant , the city of a parolar and ungen nocicities brogkpened in tEpoch 10/25\n",
      "303368/303368 [==============================] - 103s 341us/step - loss: 1.0466 - acc: 0.6809\n",
      "\n",
      "----- Generating text after Epoch: 9\n",
      "----- Generating with seed: \"s referendum , while 36 percent favored \"\n",
      "s referendum , while 36 percent favored by the siteout of manor government canidy , but iraq , and a fattorh security forces resounce and final hled boghting a bird flu by reter a dimbarin . hars kidnappen nearly spokesnays , mr. youthern officials are completed south ausing humanitarian newspapers ahabahtal . it has received and india and ungand has cances the world 's place . iraq 's taliban levers around ahmen arryad eegelay in 2001 Epoch 11/25\n",
      "303368/303368 [==============================] - 104s 341us/step - loss: 1.0167 - acc: 0.6886s - loss: 1. - ETA: 1s - loss: 1.0160 - ac - ETA: 0s - loss: 1.0164 - \n",
      "\n",
      "----- Generating text after Epoch: 10\n",
      "----- Generating with seed: \"wings by avant-garde artist and architec\"\n",
      "wings by avant-garde artist and architection to help armering china 's called the hamas 's most west bank 's north worling a secies of spokesman . meeging wemnesday in march of teerorsi has canceled to the special security confermance of mareeder in iraq of dargurie , state of bratul suidi . the indianal histerned from pruses lankmadion . media seconds seniors was deeghden huri . march thursday by carago . president hugricate 's premicaEpoch 12/25\n",
      "303368/303368 [==============================] - 103s 340us/step - loss: 0.9911 - acc: 0.6957\n",
      "\n",
      "----- Generating text after Epoch: 11\n",
      "----- Generating with seed: \"y economy and attracting foreign investm\"\n",
      "y economy and attracting foreign investmenters of american soldiers and congratuvity contractors out betines and killed at a heavy rain in six out . the statement says he said after a marck of the voce is settfedement state in two within other because it expects to relew it is wedper this week . but it would overfth effort to foreign defect to the shating in india he has been in the qear-atternatis attack on hart work from an israeli seEpoch 13/25\n",
      "303368/303368 [==============================] - 103s 340us/step - loss: 0.9682 - acc: 0.7025\n",
      "\n",
      "----- Generating text after Epoch: 12\n",
      "----- Generating with seed: \"d i will entice many partridges to you i\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d i will entice many partridges to you inriel was shepted from auriince . months in tenevise looga . it was a stronghes or negotiations . former year . loter a peavile poor cuntive next strain has a clack of nuclear president ambialthation reters thought to report oclomina decrekas and eloptage into the creatop . whet said the shooting coald forces . a u.s. plans to briging vote on a norwhy was usristry an international general dofign mEpoch 14/25\n",
      "303368/303368 [==============================] - 104s 344us/step - loss: 0.9552 - acc: 0.7051\n",
      "\n",
      "----- Generating text after Epoch: 13\n",
      "----- Generating with seed: \"st of indonesia 's sumatra island since \"\n",
      "st of indonesia 's sumatra island since a crecusabal elections and defendants , redad mee tusheq atacy to goter a graund . a fired risl accedad legdenfs toladd an american statement says a group of 73 bilitures , the man worlyws . . the demension porters are presidential duciny deris . prospert and the scuakeoul , remates . north korea working on world in what they meeting from outside a resignation forces have been killed . alemina to Epoch 15/25\n",
      "303368/303368 [==============================] - 103s 341us/step - loss: 0.9429 - acc: 0.7084\n",
      "\n",
      "----- Generating text after Epoch: 14\n",
      "----- Generating with seed: \"ade up of larger developing countries an\"\n",
      "ade up of larger developing countries and second highes commont the former powing to de a nearly powt and the united states , sasing the traveling of adghan and imports laim daw . requestly widner privised tionbe six senting last week . officials also and paille statevery afger fighting since thas in signi gree ext . intractor . issuft 2003 construction land ares of al-quida will dead atcaed with the border with a szcllys , 4n-fire on tEpoch 16/25\n",
      "303368/303368 [==============================] - 104s 341us/step - loss: 0.9257 - acc: 0.7122\n",
      "\n",
      "----- Generating text after Epoch: 15\n",
      "----- Generating with seed: \"elicopter gunships attacked enemy positi\"\n",
      "elicopter gunships attacked enemy position has been set left a men 's performerch for hurmress of form the foruogopol and captured on sunday , and the set of gave the bomb strikes presement in israel 's parliament has adpedmayentar central roth till bas troups . radar vis trought two assoming not remains including a muntri lagort in 1921 . pakistan have been disanleget he has tradency . president bush says ponengy coppan di diguase for Epoch 17/25\n",
      "303368/303368 [==============================] - 103s 341us/step - loss: 0.9160 - acc: 0.7153s - loss: 0.9159 - acc:\n",
      "\n",
      "----- Generating text after Epoch: 16\n",
      "----- Generating with seed: \" the 2002 political crisis , which trigg\"\n",
      " the 2002 political crisis , which triggeded to attack . on . on the palestinian macapourove said whint over accusing plimban into a l montals . but among deat since 1983 would be confirmed , spear at the officials in abselled two adeas . nigerial edvayer province in the calling of mosup cyrain 's military . but ressors since the failing . menia reports that showed the amanitary exploded in the northern seburitue , which ongini , which Epoch 18/25\n",
      "303368/303368 [==============================] - 103s 341us/step - loss: 0.9052 - acc: 0.7186\n",
      "\n",
      "----- Generating text after Epoch: 17\n",
      "----- Generating with seed: \" the first set with an injured hip . aga\"\n",
      " the first set with an injured hip . agapans in a jaignation along the autunan perconneg to oil araitock , which beowned that local abbastanns for their leftimm . their down placts with iraq say a sape yazur is hardainst on iraq . the committee- informading with is daily achidved the just year violent rashal center nation is redicals . thats in section-law . growzed powched a suspected says it is virgings from the muslim the family hadmEpoch 19/25\n",
      "303368/303368 [==============================] - 104s 342us/step - loss: 0.8984 - acc: 0.7202\n",
      "\n",
      "----- Generating text after Epoch: 18\n",
      "----- Generating with seed: \"shan state on november 18 , after a farm\"\n",
      "shan state on november 18 , after a farmer worndar saturday . poor, agd nigerian peacekeepors raugh said u.s. nowy possible elections . whine 's later jown in the lawies , the victims in afghanistan since , on inveuvia-ly money have been president buth leaqy tearming  . 3008 -forbiogit to firm the deplation is an iraq leader vitters says many decase since washingtons sape the president vistor arming an enelm . given attract during the cEpoch 20/25\n",
      "303368/303368 [==============================] - 104s 342us/step - loss: 0.8898 - acc: 0.7227\n",
      "\n",
      "----- Generating text after Epoch: 19\n",
      "----- Generating with seed: \" new fires . the initial fires are being\"\n",
      " new fires . the initial fires are being held to masco the northwest bank kolumeti says of a than one plact . the world tracked in residing the eve year in the western province . the finh activity in afghanistan 's hold marid thursday dethens up from $ 1939 billion , faur in fulria , china is failure cherned out sworks a hols after the attack rase in the parliamentary elice agreed to intercational israeli relition . spechasian polech anEpoch 21/25\n",
      "303368/303368 [==============================] - 104s 342us/step - loss: 0.8792 - acc: 0.7250s - los\n",
      "\n",
      "----- Generating text after Epoch: 20\n",
      "----- Generating with seed: \" 51 percent of voters support a constitu\"\n",
      " 51 percent of voters support a constitution , strose countries that two crouds have been encludence of vision uncodal heart , the united states and after their president bictht at heatt of the ban on wusher dact for mott , canurtion militants say an israeli talks , assemilan says it will relies cyochers , peruving ilan is magoring misdies from afghanistan says in nign and have dieded unice monitions in months of kenya operation give seEpoch 22/25\n",
      "303368/303368 [==============================] - 103s 340us/step - loss: 0.8757 - acc: 0.7252\n",
      "\n",
      "----- Generating text after Epoch: 21\n",
      "----- Generating with seed: \"d on by u.s. aircraft using precision-gu\"\n",
      "d on by u.s. aircraft using precision-guth children during a shi'itian officials were killed this month to undire headed agriculture , germany , tribe mr. be the cubrian group . last month 's work for the committee as possible for day 2008 . let a loceence since auwhool and many of the uprising israel , which was blared the united nations have confirmed the 2000 , on thursday and transporats . in there agricuet gred e coult of foundatioEpoch 23/25\n",
      "303368/303368 [==============================] - 103s 340us/step - loss: 0.8684 - acc: 0.7280\n",
      "\n",
      "----- Generating text after Epoch: 22\n",
      "----- Generating with seed: \"according to the report , american worke\"\n",
      "according to the report , american worked of detact and alleged rebel government and authority to allow mand wiel war in a stratetia was cartion that lobal region . dillar. , kwas minies group states and esunasder in the west . carco sharen that several of 3406 to 2009 . in januari bessing french with the 18.0 to depert ferevies in the wintars power in kye noroc planning the pro-government . the syrian prices of foreigned in the countryEpoch 24/25\n",
      "303368/303368 [==============================] - 103s 341us/step - loss: 0.8616 - acc: 0.7300\n",
      "\n",
      "----- Generating text after Epoch: 23\n",
      "----- Generating with seed: \" the official news agency , kcna , on tu\"\n",
      " the official news agency , kcna , on tursed outs the w.s strate in second three feberal . the investigation israeli sitce of the mongholoral european countries to amurion yew situits have arrested at least six discuss to interration . the group seys that attech in weeksia say the united states and the united fatah 12 % of her to necrealte security his sunday . u.s. serrec of chsutioo of amdrisher continue to stspect the owe day centlarEpoch 25/25\n",
      "303368/303368 [==============================] - 104s 343us/step - loss: 0.8597 - acc: 0.7306s - loss: 0.8589 - acc: 0. - ETA: 0s - loss: 0.8590 - a\n",
      "\n",
      "----- Generating text after Epoch: 24\n",
      "----- Generating with seed: \"llion to victims of a 1984 anti-sikh rio\"\n",
      "llion to victims of a 1984 anti-sikh riosside , the eltasing border , noath the indian vice to face praced against northern people in arnian enclanah and gut in economy in searan hassen and made the moincities . uncoustive sharrnallahk of official party laym and afghanistan launched a peeplan . in a statement tuesday , all tainon has signed in a tunse suest be coments with crossing the area of the pope of gaganation , which is forcible "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24aec4e9a20>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "modGru.fit(X_train_2, y_train_2,batch_size=256,epochs=25, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pregunta O (CuDNNGRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, logs):\n",
    "    print('\\n----- Generating text after Epoch: %d' % epoch)\n",
    "    start_index = random.randint(0, size - maxlen - 1)\n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(sentence)\n",
    "    for i in range(400):\n",
    "        next_char = predict_next_char(modCuD, sentence)\n",
    "        sentence = sentence[1:] + next_char\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "modCuD = modelCuD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "303368/303368 [==============================] - 38s 125us/step - loss: 2.4465 - acc: 0.2949\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- Generating with seed: \"mam hussein , who was killed in a battle\"\n",
      "mam hussein , who was killed in a battlee gun. ampectrighe , an laskred thay pudel . mevery inaq ervins of gath renparia ans isvesistunts tod the cespincar tos guncanith to kushing surlidgs siches in a be fursts das muss-count an offlotea 's sfer touffry ravimred to the leber hev sanured eeple e ratsity , in ta iman aman to muption said th-on mupmost crased on twapeded tro fmane , prieinge wrad codais mory an rupices say in rawian livisEpoch 2/25\n",
      "303368/303368 [==============================] - 35s 116us/step - loss: 1.8536 - acc: 0.45324 - ETA: 0s - loss: 1.8545 - acc: 0.4\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- Generating with seed: \"he position . india and burma have signe\"\n",
      "he position . india and burma have signemed , . et . sores seivions suald traces requblies to congille in 1904 and senvistive government . crilges . daymbh fushdiming cremijing foreing the ,000 leysing the \" dang he livermal was allest government make the tho leging from the reboons . the crossside bosped their wankithe . a them-and military the ronates in the went whemer 20 250 panitbe . runslaking aufomies bed miritant in official melEpoch 3/25\n",
      "303368/303368 [==============================] - 35s 116us/step - loss: 1.5905 - acc: 0.5317\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "----- Generating with seed: \"shi-khanabad , which american forces use\"\n",
      "shi-khanabad , which american forces use firld paitoroned dos the kest is in the country round in the country yevel , in least 1,000. 20d . a botw to aust of helivizy . the count in the lovests said and other senteer of istackanitws has tive of fouth of 4138 , sope ,00 earty one , \" was iranito . as the carrible olong-, dubliem borreri any a u.s. lavel have demens that russia 's faritijy and mak eupolem chriat is the wolld republic troiEpoch 4/25\n",
      "303368/303368 [==============================] - 35s 115us/step - loss: 1.4448 - acc: 0.5732\n",
      "\n",
      "----- Generating text after Epoch: 3\n",
      "----- Generating with seed: \"bush . the letter from house minority le\"\n",
      "bush . the letter from house minority leg and investigation of nexty begur eorly vasuic . the leading back on an international dorine authouities say they betted its coppaites every load house have been dichathed for with plance at a nearcy from iments of promacis frow voted . deeling file atteal president during a number of boebs and 35s500 billion as an amouny in argandad . thoshed newent . hame carref thirs poor grundine bogh 's violEpoch 5/25\n",
      "303368/303368 [==============================] - 35s 116us/step - loss: 1.3437 - acc: 0.6005\n",
      "\n",
      "----- Generating text after Epoch: 4\n",
      "----- Generating with seed: \"hite house , where they will have lunch \"\n",
      "hite house , where they will have lunch deal , after it doverno nations released part of a nator of the alleged af the rused by this month , and some fir not a meired declining that people hedioviouth conterying sumplies the veapensear . the will into may an invelvention led apcase serves in the goor 's lelarno , ceotwing united states the move thement fact government activity and kournalist week will want freech newby lececon , it willEpoch 6/25\n",
      "303368/303368 [==============================] - 35s 115us/step - loss: 1.2685 - acc: 0.6207\n",
      "\n",
      "----- Generating text after Epoch: 5\n",
      "----- Generating with seed: \"k , following charges that she violated \"\n",
      "k , following charges that she violated a tripary to his tange hols covinate to arman eurries at monut vatacity on gaida is chourder , uks qawarratif a mess in iraq play to vocations profect 's critician . it wo city of borbering a traincking indred to contitue at a gozlo$l capital toper a controver the seizhi mardinate bitanoumalday has resounces in conote from resioned to starimy bombers are collipion of sungay 's orderent swite energEpoch 7/25\n",
      "303368/303368 [==============================] - 35s 115us/step - loss: 1.2027 - acc: 0.6379\n",
      "\n",
      "----- Generating text after Epoch: 6\n",
      "----- Generating with seed: \"ple have been killed in the southern cit\"\n",
      "ple have been killed in the southern city of damage to protest in ara4ha business agency mosnow , the u.s. intolests the other duolts and southern iran to the country morders from the special of mund . taleban in african drmil prazallei , recent heaphence toinstan edeved mismils on financing , saturday , beijing . thursday . lebanishand says it han polited in patisting to pass the vity rounded laststor on nuclear were energy attacked thEpoch 8/25\n",
      "303368/303368 [==============================] - 35s 116us/step - loss: 1.1463 - acc: 0.6533\n",
      "\n",
      "----- Generating text after Epoch: 7\n",
      "----- Generating with seed: \"der sniper fire . his body armor saved h\"\n",
      "der sniper fire . his body armor saved his commenting batul bedine . u.s. officials say atol iast nuclear first side city \" bay after spoke witu nart . the zays terrorists say sold enel guilty in mid-roge than land and help dear and lifur tulnnoush refarred of the wrent oclair . loned loodes 9 for brurlials , relate to 1vanur a bargel national selucting to meepist national officials set build in urgent vayide the conflict republic , saiEpoch 9/25\n",
      "303368/303368 [==============================] - 35s 115us/step - loss: 1.0987 - acc: 0.66680s - loss: 1.0986 - ac\n",
      "\n",
      "----- Generating text after Epoch: 8\n",
      "----- Generating with seed: \"ion government . mr. katsav is to meet s\"\n",
      "ion government . mr. katsav is to meet since 1993 , but the secied leader is shi'ite a dilitire . it content the resolctor . the prima last week . tride monatchal province . share descited friday minister province on thursday . its new purscial report spannable chimp in an authiritaking . but said hrightry 's elicicial police citien are strike of walling space agreement to so the minister of the volleicher , killing about a lates freed Epoch 10/25\n",
      "303368/303368 [==============================] - 36s 120us/step - loss: 1.0545 - acc: 0.6794\n",
      "\n",
      "----- Generating text after Epoch: 9\n",
      "----- Generating with seed: \" incident . a u.s. immigration judge has\"\n",
      " incident . a u.s. immigration judge has wounded for an independent prime minister arail angara of india hak been ffection to participate . frenther wesper of wrenthar of a fubl criticized the political capital has dandara . the beanjing monday in the manjate 's occounce threatened to cint of rmisring with the recent commetting the visit . he has priceever for his winning army issued that a case now ministry started bluses who had alongEpoch 11/25\n",
      "303368/303368 [==============================] - 35s 116us/step - loss: 1.0182 - acc: 0.68921s - loss\n",
      "\n",
      "----- Generating text after Epoch: 10\n",
      "----- Generating with seed: \"fficials say two roadside bombs planted \"\n",
      "fficials say two roadside bombs planted . meanwhile , authinia is sevioimed in bagud on sharted . the british percent team are 7,5000 israelis of sufpected to the important of the fither and lid outing with the two near a terror was congress that leave secretary is not blem in the 15th and fear . he tens of the vowe he fired procrems and organizies . the the iriqe and insurgent misside with communist to three heart is likstory for vers Epoch 12/25\n",
      "303368/303368 [==============================] - 35s 116us/step - loss: 0.9906 - acc: 0.6958\n",
      "\n",
      "----- Generating text after Epoch: 11\n",
      "----- Generating with seed: \" canadian dollars ( us $ 13.73 ) . on th\"\n",
      " canadian dollars ( us $ 13.73 ) . on those workers in the capital , kjan as part of a sumare not a combuting pourn . the barbaging senior areas . the international command . ifration that he by japta mrughadd has incleded al-razating the pensol relatives of stabiling deportation , says noteing assests and trabuals . the crectors and possible , pethowes sharmailines . asular susan nations surcive through the town after israeli pease andEpoch 13/25\n",
      "303368/303368 [==============================] - 35s 116us/step - loss: 0.9663 - acc: 0.70211s\n",
      "\n",
      "----- Generating text after Epoch: 12\n",
      "----- Generating with seed: \"hed . a recent increase in violence in b\"\n",
      "hed . a recent increase in violence in baghdad , and rote the first indicate americans . beimis says thooofs -tales to omjore strike of al-qaida 's veoity government . as woll says it is tocter since 18 on maysia under to a repullicted the parestinian present of several handles of mocharing and assomatic senstory and national wust a december of percent in western decides lesisted two military says u. . dulitinate results aderusgens thatEpoch 14/25\n",
      "303368/303368 [==============================] - 35s 116us/step - loss: 0.9461 - acc: 0.70790s - loss: 0.9460 - acc: 0.7\n",
      "\n",
      "----- Generating text after Epoch: 13\n",
      "----- Generating with seed: \"rld trade organization in february , 199\"\n",
      "rld trade organization in february , 19999 . the gut his destroyicoms and u.s. zoose dournvisting the west manugation government latel this month . health fints in early 2094 , 14950 , in the west on guefflige trat photigh pirtcils of euthnews , and to lise is the shut . visit endigreated . prime minister wenker four affected by a \" hanous from the western jood have been terrorish in extrobeliget . it is not in moran but sapout weasseptEpoch 15/25\n",
      "303368/303368 [==============================] - 35s 116us/step - loss: 0.9355 - acc: 0.7103\n",
      "\n",
      "----- Generating text after Epoch: 14\n",
      "----- Generating with seed: \" reform of the education law created und\"\n",
      " reform of the education law created under partact anter the political construction profely until 19 the suspect . the new month , group has mety in the illea , says it was holding evidence with enter the leaders before a war . iran 's pare tability in the jauntry and terrorists in palling the vote counted along the dominingt . the varnes construction , repurling for east in the stofmonwol say said with a sign-donnes also repueced a fo$Epoch 16/25\n",
      "303368/303368 [==============================] - 35s 116us/step - loss: 0.9245 - acc: 0.7126\n",
      "\n",
      "----- Generating text after Epoch: 15\n",
      "----- Generating with seed: \"re leaving the mosque in dera ismail kha\"\n",
      "re leaving the mosque in dera ismail kharak those regurnty groups not entiffensement for alleged cooporation trigdert of a work to aide that his central will next year . that irents them world chink . the town of ital , khe namil wonking tax poorgerbur said they french reninien walling the line can loast , igraesing their communicy for they are reperued into a cap bast in a sear-that palestinian netwonks and that three months aired planEpoch 17/25\n",
      "303368/303368 [==============================] - 35s 116us/step - loss: 0.9169 - acc: 0.7148\n",
      "\n",
      "----- Generating text after Epoch: 16\n",
      "----- Generating with seed: \"i says she will form a new coalition gov\"\n",
      "i says she will form a new coalition government tunica served ahati still she thies woter of northern gethnent cetomicter blimes an amougstor during a roadside bomn in darfur boy to fama farm . butt heavy washington to discovery energy emerged country dispets . separatels , he assess that decisions to ampedem a bradelly trapf the annummed sanctions aurging hadas , on smandown falling britesh president talks with unallel and which tried Epoch 18/25\n",
      "303368/303368 [==============================] - 35s 116us/step - loss: 0.9114 - acc: 0.7166\n",
      "\n",
      "----- Generating text after Epoch: 17\n",
      "----- Generating with seed: \"derail next month 's national elections \"\n",
      "derail next month 's national elections in the northeast . a 2002 brusded will return for another comment in 2009 . the u.s. military hidered as have been unumeeted by the team is wonking a lingen to two million for the gall . the palestinian and outbility . nationalities say a political propore \" u.s. military four mayn for scheduled at entry lange cunturn manughancon , says it as saystend nex leare friday that notbe juil , which ccoutEpoch 19/25\n",
      "303368/303368 [==============================] - 35s 116us/step - loss: 0.9142 - acc: 0.71470s - loss: 0.9131 - acc: 0 - ETA: 0s - loss: 0.9132 - a\n",
      "\n",
      "----- Generating text after Epoch: 18\n",
      "----- Generating with seed: \"s salvage a disappointing holiday shoppi\"\n",
      "s salvage a disappointing holiday shoppia spich of sandah 's voosed bus lanese region , mr. bushs hilled the end of abothin health rebel urabiema said the treater , has killed discusses because of the u.s. concerns vot chrestery . after food and wranghing in gaza stric , in aula in the -strit to work and kind chinese depected of participates the dollor was scond to 1.1 , which talks in bedirration is allor develop at the candidate , whiEpoch 20/25\n",
      "303368/303368 [==============================] - 35s 116us/step - loss: 0.9091 - acc: 0.7165\n",
      "\n",
      "----- Generating text after Epoch: 19\n",
      "----- Generating with seed: \" where shi'ite muslim pilgrims are conve\"\n",
      " where shi'ite muslim pilgrims are convelted department spoke months . they undermare thorsan ,0,000 and ogapa encorrerso in the beire of narth roder . smanitor gords to crock were simplinis to office from pakistan because of all givinm to import to vain the epeconding % . published spans of the group focomaced by unumgu chene coording to the revenue , and the meeting , believes the dorlars with north korean opposition , central ammintiEpoch 21/25\n",
      "303368/303368 [==============================] - 35s 116us/step - loss: 0.9074 - acc: 0.7172\n",
      "\n",
      "----- Generating text after Epoch: 20\n",
      "----- Generating with seed: \"them in the fold . he gave his own goats\"\n",
      "them in the fold . he gave his own goats , north korean police say at mech a close troops were hold protesters and expected in berghn , the sypension from the economy from judg , dost of the openation for rack has been sixred from reinfill west caneirn-lod for israel 's most five marklesi planning about a new giols and police compiting u. . in the government between coroneting tenta . a panded on palestinian militant reports that the heEpoch 22/25\n",
      "303368/303368 [==============================] - 35s 116us/step - loss: 0.9041 - acc: 0.71781s - loss:\n",
      "\n",
      "----- Generating text after Epoch: 21\n",
      "----- Generating with seed: \" has crashed northwest of baghdad . ther\"\n",
      " has crashed northwest of baghdad . there yran that the government says dim killand also assests a pay by their calls for recently latt adrinved ty help of the pahel in a lower to mr. nisis and also been those the indernies for at least 200 files deciding for informed some missile , the source of numantsed ifferting serving aid at least one that is concince . rebirs said the plann to camimanian badicut that several capsublication in novEpoch 23/25\n",
      "303368/303368 [==============================] - 35s 115us/step - loss: 0.9065 - acc: 0.7164\n",
      "\n",
      "----- Generating text after Epoch: 22\n",
      "----- Generating with seed: \" the entire gulf coast region and warned\"\n",
      " the entire gulf coast region and warned decharstants are smieli were in the 16ts . earliar military officials have not enterstail in the gear . the afghan arrivisi nations quict outside the 35-year-els . the country is boandana markan . the u.s. military officials had edplided in when a southeast attack that the former a traff cammed a -loal stape . the u.s. northwest of the town . it caunding the palestinian country , of birds flow hoEpoch 24/25\n",
      "303368/303368 [==============================] - 35s 115us/step - loss: 0.9073 - acc: 0.7162\n",
      "\n",
      "----- Generating text after Epoch: 23\n",
      "----- Generating with seed: \"auxite / alumina . remittances account f\"\n",
      "auxite / alumina . remittances account for coalition forces have been unimed about 16 people deddist the country for genous at acon members of votes accused the group say the efforts of its longhan in 2004 . a suicide bomber , where the first lireounce , in the dars , secarother , gyri . rebels were expected to be denied conomeers and former diving of prime minister ariai . in the campaign union leading requorts to press stateed a siftlEpoch 25/25\n",
      "303368/303368 [==============================] - 35s 115us/step - loss: 0.9121 - acc: 0.7144\n",
      "\n",
      "----- Generating text after Epoch: 24\n",
      "----- Generating with seed: \" than a third of those with depression r\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " than a third of those with depression recented strike with make officials hode to allow bush , russian term of under hossia bilitions or two istans , macro resulted the western regines . the name of a group on palling for the u.s. shilite and meetings . boiting iner of palestinian authorities say a tatilling in 2006 doan redeired a six prisoners . in violence saturday in mexturing in afghanistan has refearsing into a friday fas the bom"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24b09c9a5c0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "modCuD.fit(X_train_2, y_train_2,batch_size=256,epochs=25, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> La técnica es cambiando los valores de la función randint a los valores más cercanos de los esperados, los valores se cambian con el entrenamiento de red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pregunta P (GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Generating with seed: \"it is \"\n",
      "it is seet well and a regueance , wmicted but that hushere 's held two muk as his for the approval , the new foreal nationatile day aspear his provina in wednes blume nine with preside terror , the still deccary the united repire shilina in center grants watted opposes the cauteoral the protes the moneparanelesking the capture thursda in record wiles techonal wedees , wespens , and anrisu est africa , w"
     ]
    }
   ],
   "source": [
    "sentence = \"it is \"\n",
    "print('----- Generating with seed: \"' + sentence + '\"')\n",
    "sys.stdout.write(sentence)\n",
    "for i in range(400):\n",
    "    next_char = predict_next_char(modGru, sentence)\n",
    "    sentence = sentence[1:] + next_char \n",
    "    sys.stdout.write(next_char)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pregunta  P (CuDNNGRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Generating with seed: \"it is \"\n",
      "it is may efficite . in the hore . he says of zean north during bories convict is came the for party . chines of his search of a reporters , a reacres , congres . new person is doment , bochar of barin and latest level-state . englishon national carriel his ortana maheled aloun emergen afghan euctadak . it step an engode . a surmon , the companed is to report effort and nearly , the his export for that "
     ]
    }
   ],
   "source": [
    "sentence = \"it is \"\n",
    "print('----- Generating with seed: \"' + sentence + '\"')\n",
    "sys.stdout.write(sentence)\n",
    "for i in range(400):\n",
    "    next_char = predict_next_char(modCuD, sentence)\n",
    "    sentence = sentence[1:] + next_char \n",
    "    sys.stdout.write(next_char)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Las frases generadas harían mucho menos sentido porque el efecto de la red sería mucho más sensible, así que el hecho de haber generado una frase con un sentido intetecto dice que la red fue entrenada de manera correcta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
